--- a/home/whalien/codebase/cpp/mergebot/eva/output/duckdb/ea6567fe-d84e329b-9de6e816/tools@pythonpkg@src@pyconnection.no_comments_mergebot.cpp
+++ b/home/whalien/codebase/cpp/mergebot/eva/output/duckdb/ea6567fe-d84e329b-9de6e816/tools@pythonpkg@src@pyconnection.no_comments_merged.cpp
@@ -1 +0,0 @@
-#include "duckdb_python/pyconnection.hpp"
@@ -25,2 +23,0 @@
-#include "duckdb_python/arrow_array_stream.hpp"
-#include "duckdb_python/pandas_scan.hpp"
@@ -33,0 +31 @@
+#include "duckdb/main/prepared_statement.hpp"
@@ -35,0 +34,5 @@
+#include "duckdb/main/client_config.hpp"
+#include "duckdb/function/table/read_csv.hpp"
+#include "duckdb/common/enums/file_compression_type.hpp"
+#include "duckdb/catalog/default/default_types.hpp"
+#include "duckdb/main/relation/value_relation.hpp"
@@ -37,0 +41 @@
+#include "duckdb/common/printer.hpp"
@@ -39 +43 @@ namespace duckdb {
-PythonEnvironmentType DuckDBPyConnection::environment = PythonEnvironmentType::NORMAL;
+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::default_connection = nullptr;
@@ -40,0 +45 @@ DBInstanceCache instance_cache;
+shared_ptr<PythonImportCache> DuckDBPyConnection::import_cache = nullptr;
@@ -42,156 +47,4 @@ PythonEnvironmentType DuckDBPyConnection::environment = PythonEnvironmentType::N
-PythonEnvironmentType DuckDBPyConnection::environment = PythonEnvironmentType::NORMAL;
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
+void DuckDBPyConnection::DetectEnvironment() {
+ auto main_module = py::module_::import("__main__");
+ if (py::hasattr(main_module, "__file__")) {
+  return;
@@ -198,0 +52,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ DuckDBPyConnection::environment = PythonEnvironmentType::INTERACTIVE;
+ if (!ModuleIsLoaded<IPythonCacheItem>()) {
+  return;
@@ -199,0 +56,4 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ auto &import_cache_py = *DuckDBPyConnection::ImportCache();
+ auto get_ipython = import_cache_py.IPython().get_ipython();
+ if (get_ipython.ptr() == nullptr) {
+  return;
@@ -201 +61,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ auto ipython = get_ipython();
+ if (!py::hasattr(ipython, "config")) {
+  return;
@@ -203,13 +65,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
+ py::dict ipython_config = ipython.attr("config");
+ if (ipython_config.contains("IPKernelApp")) {
+  DuckDBPyConnection::environment = PythonEnvironmentType::JUPYTER;
@@ -217 +69 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ return;
@@ -219,2 +71,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- default:
-  throw NotImplementedException("Unsupported pandas type");
+bool DuckDBPyConnection::DetectAndGetEnvironment() {
+ DuckDBPyConnection::DetectEnvironment();
+ return DuckDBPyConnection::IsInteractive();
@@ -221,0 +75,2 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+bool DuckDBPyConnection::IsJupyter() {
+ return DuckDBPyConnection::environment == PythonEnvironmentType::JUPYTER;
@@ -251,360 +105,0 @@ py::object ArrowTableFromDataframe(const py::object &df) {
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
@@ -719,50 +214,20 @@ static void InitializeConnectionMethods(py::class_<DuckDBPyConnection, shared_pt
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
+void DuckDBPyConnection::UnregisterFilesystem(const py::str &name) {
+ auto &fs = database->GetFileSystem();
+ fs.UnregisterSubSystem(name);
+}
+void DuckDBPyConnection::RegisterFilesystem(AbstractFileSystem filesystem) {
+ PythonGILWrapper gil_wrapper;
+ if (!py::isinstance<AbstractFileSystem>(filesystem)) {
+  throw InvalidInputException("Bad filesystem instance");
+ }
+ auto &fs = database->GetFileSystem();
+ auto protocol = filesystem.attr("protocol");
+ if (protocol.is_none() || py::str("abstract").equal(protocol)) {
+  throw InvalidInputException("Must provide concrete fsspec implementation");
+ }
+ vector<string> protocols;
+ if (py::isinstance<py::str>(protocol)) {
+  protocols.push_back(py::str(protocol));
+ } else {
+  for (const auto &sub_protocol : protocol) {
+   protocols.push_back(py::str(sub_protocol));
@@ -770 +234,0 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
@@ -772,20 +236 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
+ fs.RegisterSubSystem(make_uniq<PythonFilesystem>(std::move(protocols), std::move(filesystem)));
@@ -793 +238,5 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+py::list DuckDBPyConnection::ListFilesystems() {
+ auto subsystems = database->GetFileSystem().ListSubSystems();
+ py::list names;
+ for (auto &name : subsystems) {
+  names.append(py::str(name));
@@ -795,4 +244,14 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
+ return names;
+}
+bool DuckDBPyConnection::FileSystemIsRegistered(const string &name) {
+ auto subsystems = database->GetFileSystem().ListSubSystems();
+ return std::find(subsystems.begin(), subsystems.end(), name) != subsystems.end();
+}
+void DuckDBPyConnection::Initialize(py::handle &m) {
+ auto connection_module =
+     py::class_<DuckDBPyConnection, shared_ptr<DuckDBPyConnection>>(m, "DuckDBPyConnection", py::module_local());
+ connection_module.def("__enter__", &DuckDBPyConnection::Enter)
+     .def("__exit__", &DuckDBPyConnection::Exit, py::arg("exc_type"), py::arg("exc"), py::arg("traceback"));
+ InitializeConnectionMethods(connection_module);
+ PyDateTime_IMPORT;
+ DuckDBPyConnection::ImportCache();
@@ -800,74 +259,15 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::ExecuteMany(const string &query, py::object params) {
+ if (params.is_none()) {
+  params = py::list();
+ }
+ Execute(query, std::move(params), true);
+ return shared_from_this();
+}
+unique_ptr<QueryResult> DuckDBPyConnection::CompletePendingQuery(PendingQueryResult &pending_query) {
+ PendingExecutionResult execution_result;
+ do {
+  execution_result = pending_query.ExecuteTask();
+  {
+   py::gil_scoped_acquire gil;
+   if (PyErr_CheckSignals() != 0) {
+    throw std::runtime_error("Query interrupted");
@@ -875,0 +276,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ } while (execution_result == PendingExecutionResult::RESULT_NOT_READY);
+ if (execution_result == PendingExecutionResult::EXECUTION_ERROR) {
+  pending_query.ThrowError();
@@ -877 +280 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ return pending_query.Execute();
@@ -879,13 +282,9 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
+py::list TransformNamedParameters(const case_insensitive_map_t<idx_t> &named_param_map, const py::dict &params) {
+ py::list new_params(params.size());
+ for (auto &item : params) {
+  const std::string &item_name = item.first.cast<std::string>();
+  auto entry = named_param_map.find(item_name);
+  if (entry == named_param_map.end()) {
+   throw InvalidInputException(
+       "Named parameters could not be transformed, because query string is missing named parameter '%s'",
+       item_name);
@@ -893 +292,214 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+  auto param_idx = entry->second;
+  new_params[param_idx - 1] = item.second;
+ }
+ if (named_param_map.size() != params.size()) {
+  vector<string> missing_params;
+  missing_params.reserve(named_param_map.size());
+  for (auto &entry : named_param_map) {
+   auto &name = entry.first;
+   if (!params.contains(name)) {
+    missing_params.push_back(name);
+   }
+  }
+  auto message = StringUtil::Join(missing_params, ", ");
+  throw InvalidInputException("Not all named parameters have been located, missing: %s", message);
+ }
+ return new_params;
+}
+unique_ptr<QueryResult> DuckDBPyConnection::ExecuteInternal(const string &query, py::object params, bool many) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ if (params.is_none()) {
+  params = py::list();
+ }
+ result = nullptr;
+ unique_ptr<PreparedStatement> prep;
+ {
+  py::gil_scoped_release release;
+  unique_lock<std::mutex> lock(py_connection_lock);
+  auto statements = connection->ExtractStatements(query);
+  if (statements.empty()) {
+   return nullptr;
+  }
+  for (idx_t i = 0; i + 1 < statements.size(); i++) {
+   auto pending_query = connection->PendingQuery(std::move(statements[i]), false);
+   auto res = CompletePendingQuery(*pending_query);
+   if (res->HasError()) {
+    res->ThrowError();
+   }
+  }
+  prep = connection->Prepare(std::move(statements.back()));
+  if (prep->HasError()) {
+   prep->error.Throw();
+  }
+ }
+ auto &named_param_map = prep->named_param_map;
+ if (py::isinstance<py::dict>(params)) {
+  if (named_param_map.empty()) {
+   throw InvalidInputException("Param is of type 'dict', but no named parameters were found in the query");
+  }
+  params = TransformNamedParameters(named_param_map, params);
+  prep->named_param_map.clear();
+ } else if (!named_param_map.empty()) {
+  throw InvalidInputException("Named parameters found, but param is not of type 'dict'");
+ }
+ py::list params_set;
+ if (!many) {
+  params_set = py::list(1);
+  params_set[0] = params;
+ } else {
+  params_set = params;
+ }
+ for (pybind11::handle single_query_params : params_set) {
+  if (prep->n_param != py::len(single_query_params)) {
+   throw InvalidInputException("Prepared statement needs %d parameters, %d given", prep->n_param,
+                               py::len(single_query_params));
+  }
+  auto args = DuckDBPyConnection::TransformPythonParamList(single_query_params);
+  unique_ptr<QueryResult> res;
+  {
+   py::gil_scoped_release release;
+   unique_lock<std::mutex> lock(py_connection_lock);
+   auto pending_query = prep->PendingQuery(args);
+   res = CompletePendingQuery(*pending_query);
+   if (res->HasError()) {
+    res->ThrowError();
+   }
+  }
+  if (!many) {
+   return res;
+  }
+ }
+ return nullptr;
+}
+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Execute(const string &query, py::object params, bool many) {
+ auto res = ExecuteInternal(query, std::move(params), many);
+ if (res) {
+  auto py_result = make_uniq<DuckDBPyResult>(std::move(res));
+  result = make_uniq<DuckDBPyRelation>(std::move(py_result));
+ }
+ return shared_from_this();
+}
+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Append(const string &name, const DataFrame &value) {
+ RegisterPythonObject("__append_df", value);
+ return Execute("INSERT INTO \"" + name + "\" SELECT * FROM __append_df");
+}
+void DuckDBPyConnection::RegisterArrowObject(const py::object &arrow_object, const string &name) {
+ auto stream_factory =
+     make_uniq<PythonTableArrowArrayStreamFactory>(arrow_object.ptr(), connection->context->config);
+ auto stream_factory_produce = PythonTableArrowArrayStreamFactory::Produce;
+ auto stream_factory_get_schema = PythonTableArrowArrayStreamFactory::GetSchema;
+ {
+  py::gil_scoped_release release;
+  temporary_views[name] =
+      connection
+          ->TableFunction("arrow_scan", {Value::POINTER((uintptr_t)stream_factory.get()),
+                                         Value::POINTER((uintptr_t)stream_factory_produce),
+                                         Value::POINTER((uintptr_t)stream_factory_get_schema)})
+          ->CreateView(name, true, true);
+ }
+ vector<shared_ptr<ExternalDependency>> dependencies;
+ dependencies.push_back(
+     make_shared<PythonDependencies>(make_uniq<RegisteredArrow>(std::move(stream_factory), arrow_object)));
+ connection->context->external_dependencies[name] = std::move(dependencies);
+}
+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::RegisterPythonObject(const string &name,
+                                                                        const py::object &python_object) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ if (DuckDBPyConnection::IsPandasDataframe(python_object)) {
+  if (IsArrowBackedDataFrame(python_object)) {
+   auto arrow_table = ArrowTableFromDataframe(python_object);
+   RegisterArrowObject(arrow_table, name);
+  } else {
+   auto new_df = PandasScanFunction::PandasReplaceCopiedNames(python_object);
+   {
+    py::gil_scoped_release release;
+    temporary_views[name] =
+        connection->TableFunction("pandas_scan", {Value::POINTER((uintptr_t)new_df.ptr())})
+            ->CreateView(name, true, true);
+   }
+   vector<shared_ptr<ExternalDependency>> dependencies;
+   dependencies.push_back(make_shared<PythonDependencies>(make_uniq<RegisteredObject>(python_object),
+                                                          make_uniq<RegisteredObject>(new_df)));
+   connection->context->external_dependencies[name] = std::move(dependencies);
+  }
+ } else if (IsAcceptedArrowObject(python_object) || IsPolarsDataframe(python_object)) {
+  py::object arrow_object;
+  if (IsPolarsDataframe(python_object)) {
+   if (PolarsDataFrame::IsDataFrame(python_object)) {
+    arrow_object = python_object.attr("to_arrow")();
+   } else if (PolarsDataFrame::IsLazyFrame(python_object)) {
+    py::object materialized = python_object.attr("collect")();
+    arrow_object = materialized.attr("to_arrow")();
+   } else {
+    throw NotImplementedException("Unsupported Polars DF Type");
+   }
+  } else {
+   arrow_object = python_object;
+  }
+  RegisterArrowObject(arrow_object, name);
+ } else if (DuckDBPyRelation::IsRelation(python_object)) {
+  auto pyrel = py::cast<DuckDBPyRelation *>(python_object);
+  pyrel->CreateView(name, true);
+ } else {
+  auto py_object_type = string(py::str(python_object.get_type().attr("__name__")));
+  throw InvalidInputException("Python Object %s not suitable to be registered as a view", py_object_type);
+ }
+ return shared_from_this();
+}
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::ReadJSON(const string &name, const py::object &columns,
+                                                          const py::object &sample_size,
+                                                          const py::object &maximum_depth) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ named_parameter_map_t options;
+ if (!py::none().is(columns)) {
+  if (!py::isinstance<py::dict>(columns)) {
+   throw InvalidInputException("read_json only accepts 'columns' as a dict[str, str]");
+  }
+  py::dict columns_dict = columns;
+  child_list_t<Value> struct_fields;
+  for (auto &kv : columns_dict) {
+   auto &column_name = kv.first;
+   auto &type = kv.second;
+   if (!py::isinstance<py::str>(column_name)) {
+    string actual_type = py::str(column_name.get_type());
+    throw InvalidInputException("The provided column name must be a str, not of type '%s'", actual_type);
+   }
+   if (!py::isinstance<py::str>(type)) {
+    string actual_type = py::str(column_name.get_type());
+    throw InvalidInputException("The provided column type must be a str, not of type '%s'", actual_type);
+   }
+   struct_fields.emplace_back(py::str(column_name), Value(py::str(type)));
+  }
+  auto dtype_struct = Value::STRUCT(std::move(struct_fields));
+  options["columns"] = std::move(dtype_struct);
+ }
+ if (!py::none().is(sample_size)) {
+  if (!py::isinstance<py::int_>(sample_size)) {
+   string actual_type = py::str(sample_size.get_type());
+   throw InvalidInputException("read_json only accepts 'sample_size' as an integer, not '%s'", actual_type);
+  }
+  options["sample_size"] = Value::INTEGER(py::int_(sample_size));
+ }
+ if (!py::none().is(maximum_depth)) {
+  if (!py::isinstance<py::int_>(maximum_depth)) {
+   string actual_type = py::str(maximum_depth.get_type());
+   throw InvalidInputException("read_json only accepts 'maximum_depth' as an integer, not '%s'", actual_type);
+  }
+  options["maximum_depth"] = Value::INTEGER(py::int_(maximum_depth));
+ }
+ bool auto_detect = false;
+ if (!options.count("columns")) {
+  options["auto_detect"] = Value::BOOLEAN(true);
+  auto_detect = true;
+ }
+ auto read_json_relation = make_shared<ReadJSONRelation>(connection->context, name, std::move(options), auto_detect);
+ if (read_json_relation == nullptr) {
+  throw InvalidInputException("read_json can only be used when the JSON extension is (statically) loaded");
+ }
+ return make_uniq<DuckDBPyRelation>(std::move(read_json_relation));
@@ -895,2 +507,2 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- default:
-  throw NotImplementedException("Unsupported pandas type");
+PathLike DuckDBPyConnection::GetPathLike(const py::object &object) {
+ return PathLike::Create(object, *this);
@@ -897,0 +510,8 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::ReadCSV(
+    const py::object &name_p, const py::object &header, const py::object &compression, const py::object &sep,
+    const py::object &delimiter, const py::object &dtype, const py::object &na_values, const py::object &skiprows,
+    const py::object &quotechar, const py::object &escapechar, const py::object &encoding, const py::object &parallel,
+    const py::object &date_format, const py::object &timestamp_format, const py::object &sample_size,
+    const py::object &all_varchar, const py::object &normalize_names, const py::object &filename) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
@@ -899,50 +519,12 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
+ BufferedCSVReaderOptions options;
+ auto path_like = GetPathLike(name_p);
+ auto &name = path_like.str;
+ auto file_like_object_wrapper = std::move(path_like.dependency);
+ if (!py::none().is(header)) {
+  bool header_as_int = py::isinstance<py::int_>(header);
+  bool header_as_bool = py::isinstance<py::bool_>(header);
+  if (header_as_bool) {
+   options.SetHeader(py::bool_(header));
+  } else if (header_as_int) {
+   if ((int)py::int_(header) != 0) {
+    throw InvalidInputException("read_csv only accepts 0 if 'header' is given as an integer");
@@ -950 +532,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+   options.SetHeader(true);
+  } else {
+   throw InvalidInputException("read_csv only accepts 'header' as an integer, or a boolean");
@@ -952,20 +535,0 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
@@ -973 +537,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ if (!py::none().is(compression)) {
+  if (!py::isinstance<py::str>(compression)) {
+   throw InvalidInputException("read_csv only accepts 'compression' as a string");
@@ -975,4 +541 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
+  options.SetCompression(py::str(compression));
@@ -980,74 +543,5 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
+ auto read_csv_p = connection->ReadCSV(name, options);
+ auto &read_csv = (ReadCSVRelation &)*read_csv_p;
+ if (file_like_object_wrapper) {
+  D_ASSERT(!read_csv.extra_dependencies);
+  read_csv.extra_dependencies = std::move(file_like_object_wrapper);
@@ -1054,0 +549,2 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ if (options.has_header) {
+  read_csv.AddNamedParameter("header", Value::BOOLEAN(options.header));
@@ -1055,0 +552,2 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ if (options.compression != FileCompressionType::AUTO_DETECT) {
+  read_csv.AddNamedParameter("compression", Value(py::str(compression)));
@@ -1057 +555,4 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ bool has_sep = !py::none().is(sep);
+ bool has_delimiter = !py::none().is(delimiter);
+ if (has_sep && has_delimiter) {
+  throw InvalidInputException("read_csv takes either 'delimiter' or 'sep', not both");
@@ -1059,13 +560,4 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
+ if (has_sep) {
+  read_csv.AddNamedParameter("delim", Value(py::str(sep)));
+ } else if (has_delimiter) {
+  read_csv.AddNamedParameter("delim", Value(py::str(delimiter)));
@@ -1073 +565,6 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ if (!py::none().is(dtype)) {
+  if (py::isinstance<py::dict>(dtype)) {
+   child_list_t<Value> struct_fields;
+   py::dict dtype_dict = dtype;
+   for (auto &kv : dtype_dict) {
+    struct_fields.emplace_back(py::str(kv.first), Value(py::str(kv.second)));
@@ -1075,2 +572,9 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- default:
-  throw NotImplementedException("Unsupported pandas type");
+   auto dtype_struct = Value::STRUCT(std::move(struct_fields));
+   read_csv.AddNamedParameter("dtypes", std::move(dtype_struct));
+  } else if (py::isinstance<py::list>(dtype)) {
+   auto dtype_list = TransformPythonValue(py::list(dtype));
+   D_ASSERT(dtype_list.type().id() == LogicalTypeId::LIST);
+   auto &children = ListValue::GetChildren(dtype_list);
+   for (auto &child : children) {
+    if (child.type().id() != LogicalTypeId::VARCHAR) {
+     throw InvalidInputException("The types provided to 'dtype' have to be strings");
@@ -1079,50 +583,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
+   read_csv.AddNamedParameter("dtypes", std::move(dtype_list));
+  } else {
+   throw InvalidInputException("read_csv only accepts 'dtype' as a dictionary or a list of strings");
@@ -1130 +586,0 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
@@ -1132,20 +588,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
+ if (!py::none().is(na_values)) {
+  if (!py::isinstance<py::str>(na_values)) {
+   throw InvalidInputException("read_csv only accepts 'na_values' as a string");
@@ -1153 +592 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+  read_csv.AddNamedParameter("nullstr", Value(py::str(na_values)));
@@ -1155,4 +594,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
+ if (!py::none().is(skiprows)) {
+  if (!py::isinstance<py::int_>(skiprows)) {
+   throw InvalidInputException("read_csv only accepts 'skiprows' as an integer");
@@ -1160,74 +598 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
+  read_csv.AddNamedParameter("skip", Value::INTEGER(py::int_(skiprows)));
@@ -1234,0 +600,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ if (!py::none().is(parallel)) {
+  if (!py::isinstance<py::bool_>(parallel)) {
+   throw InvalidInputException("read_csv only accepts 'parallel' as a boolean");
@@ -1235,0 +604 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+  read_csv.AddNamedParameter("parallel", Value::BOOLEAN(py::bool_(parallel)));
@@ -1237 +606,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ if (!py::none().is(quotechar)) {
+  if (!py::isinstance<py::str>(quotechar)) {
+   throw InvalidInputException("read_csv only accepts 'quotechar' as a string");
@@ -1239,13 +610 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
+  read_csv.AddNamedParameter("quote", Value(py::str(quotechar)));
@@ -1253 +612,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ if (!py::none().is(escapechar)) {
+  if (!py::isinstance<py::str>(escapechar)) {
+   throw InvalidInputException("read_csv only accepts 'escapechar' as a string");
@@ -1255,2 +616 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- default:
-  throw NotImplementedException("Unsupported pandas type");
+  read_csv.AddNamedParameter("escape", Value(py::str(escapechar)));
@@ -1257,0 +618,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ if (!py::none().is(encoding)) {
+  if (!py::isinstance<py::str>(encoding)) {
+   throw InvalidInputException("read_csv only accepts 'encoding' as a string");
@@ -1259,50 +622,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
+  string encoding_str = StringUtil::Lower(py::str(encoding));
+  if (encoding_str != "utf8" && encoding_str != "utf-8") {
+   throw BinderException("Copy is only supported for UTF-8 encoded files, ENCODING 'UTF-8'");
@@ -1310 +625,0 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
@@ -1312,20 +627,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
+ if (!py::none().is(date_format)) {
+  if (!py::isinstance<py::str>(date_format)) {
+   throw InvalidInputException("read_csv only accepts 'date_format' as a string");
@@ -1333 +631 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+  read_csv.AddNamedParameter("dateformat", Value(py::str(date_format)));
@@ -1335,4 +633,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
+ if (!py::none().is(timestamp_format)) {
+  if (!py::isinstance<py::str>(timestamp_format)) {
+   throw InvalidInputException("read_csv only accepts 'timestamp_format' as a string");
@@ -1340,74 +637 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
+  read_csv.AddNamedParameter("timestampformat", Value(py::str(timestamp_format)));
@@ -1414,0 +639,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ if (!py::none().is(sample_size)) {
+  if (!py::isinstance<py::int_>(sample_size)) {
+   throw InvalidInputException("read_csv only accepts 'sample_size' as an integer");
@@ -1415,0 +643 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+  read_csv.AddNamedParameter("sample_size", Value::INTEGER(py::int_(sample_size)));
@@ -1417 +645,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ if (!py::none().is(all_varchar)) {
+  if (!py::isinstance<py::bool_>(all_varchar)) {
+   throw InvalidInputException("read_csv only accepts 'all_varchar' as a boolean");
@@ -1419,13 +649 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
+  read_csv.AddNamedParameter("all_varchar", Value::INTEGER(py::bool_(all_varchar)));
@@ -1433 +651,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ if (!py::none().is(normalize_names)) {
+  if (!py::isinstance<py::bool_>(normalize_names)) {
+   throw InvalidInputException("read_csv only accepts 'normalize_names' as a boolean");
@@ -1435,2 +655 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- default:
-  throw NotImplementedException("Unsupported pandas type");
+  read_csv.AddNamedParameter("normalize_names", Value::INTEGER(py::bool_(normalize_names)));
@@ -1437,0 +657,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ if (!py::none().is(filename)) {
+  if (!py::isinstance<py::bool_>(filename)) {
+   throw InvalidInputException("read_csv only accepts 'filename' as a boolean");
@@ -1439,50 +661 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
+  read_csv.AddNamedParameter("filename", Value::INTEGER(py::bool_(filename)));
@@ -1490 +663 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ return make_uniq<DuckDBPyRelation>(read_csv_p->Alias(name));
@@ -1492,20 +665,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromQuery(const string &query, const string &alias) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
@@ -1513 +669,5 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ const char *duckdb_query_error = R"(duckdb.from_query cannot be used to run arbitrary SQL queries.
+It can only be used to run individual SELECT statements, and converts the result of that SELECT
+statement into a Relation object.
+Use duckdb.sql to run arbitrary SQL queries.)";
+ return make_uniq<DuckDBPyRelation>(connection->RelationFromQuery(query, alias, duckdb_query_error));
@@ -1515,4 +675,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::RunQuery(const string &query, const string &alias) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
@@ -1520,74 +679,5 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
+ Parser parser(connection->context->GetParserOptions());
+ parser.ParseQuery(query);
+ if (parser.statements.size() == 1 && parser.statements[0]->type == StatementType::SELECT_STATEMENT) {
+  return make_uniq<DuckDBPyRelation>(connection->RelationFromQuery(
+      unique_ptr_cast<SQLStatement, SelectStatement>(std::move(parser.statements[0])), alias));
@@ -1594,0 +685,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ auto res = ExecuteInternal(query);
+ if (!res) {
+  return nullptr;
@@ -1595,0 +689,2 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ if (res->properties.return_type != StatementReturnType::QUERY_RESULT) {
+  return nullptr;
@@ -1596,0 +692,5 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ vector<vector<Value>> values;
+ vector<string> names = res->names;
+ while (true) {
+  auto chunk = res->Fetch();
+  if (!chunk || chunk->size() == 0) {
@@ -1599,13 +699,4 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
+  for (idx_t r = 0; r < chunk->size(); r++) {
+   vector<Value> row;
+   for (idx_t c = 0; c < chunk->ColumnCount(); c++) {
+    row.push_back(chunk->data[c].GetValue(r));
@@ -1613 +704 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+   values.push_back(std::move(row));
@@ -1615,2 +705,0 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- default:
-  throw NotImplementedException("Unsupported pandas type");
@@ -1617,0 +707,2 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ if (values.empty()) {
+  return nullptr;
@@ -1619,50 +710 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
+ return make_uniq<DuckDBPyRelation>(make_uniq<ValueRelation>(connection->context, values, names));
@@ -1670 +712,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::Table(const string &tname) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
@@ -1672,20 +716,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
+ auto qualified_name = QualifiedName::Parse(tname);
+ if (qualified_name.schema.empty()) {
+  qualified_name.schema = DEFAULT_SCHEMA;
@@ -1693 +720 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ return make_uniq<DuckDBPyRelation>(connection->Table(qualified_name.schema, qualified_name.name));
@@ -1695,4 +722,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::Values(py::object params) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
@@ -1700,74 +726,2 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
+ if (params.is_none()) {
+  params = py::list();
@@ -1774,0 +729,2 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ if (!py::hasattr(params, "__len__")) {
+  throw InvalidInputException("Type of object passed to parameter 'values' must be iterable");
@@ -1775,0 +732,2 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ vector<vector<Value>> values {DuckDBPyConnection::TransformPythonParamList(params)};
+ return make_uniq<DuckDBPyRelation>(connection->Values(values));
@@ -1777 +735,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::View(const string &vname) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
@@ -1779,11175 +739,159 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
- }
- default:
-  throw NotImplementedException("Unsupported pandas type");
- }
-}
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
-  }
-  break;
+ if (temporary_views.find(vname) != temporary_views.end()) {
+  return make_uniq<DuckDBPyRelation>(temporary_views[vname]);
+ }
+ return make_uniq<DuckDBPyRelation>(connection->View(vname));
+}
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::TableFunction(const string &fname, py::object params) {
+ if (params.is_none()) {
+  params = py::list();
+ }
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ return make_uniq<DuckDBPyRelation>(
+     connection->TableFunction(fname, DuckDBPyConnection::TransformPythonParamList(params)));
+}
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromDF(const DataFrame &value) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ string name = "df_" + StringUtil::GenerateRandomName();
+ if (IsArrowBackedDataFrame(value)) {
+  auto table = ArrowTableFromDataframe(value);
+  return DuckDBPyConnection::FromArrow(table);
+ }
+ auto new_df = PandasScanFunction::PandasReplaceCopiedNames(value);
+ vector<Value> params;
+ params.emplace_back(Value::POINTER((uintptr_t)new_df.ptr()));
+ auto rel = connection->TableFunction("pandas_scan", params)->Alias(name);
+ rel->extra_dependencies =
+     make_uniq<PythonDependencies>(make_uniq<RegisteredObject>(value), make_uniq<RegisteredObject>(new_df));
+ return make_uniq<DuckDBPyRelation>(std::move(rel));
+}
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquet(const string &file_glob, bool binary_as_string,
+                                                             bool file_row_number, bool filename,
+                                                             bool hive_partitioning, bool union_by_name,
+                                                             const py::object &compression) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ string name = "parquet_" + StringUtil::GenerateRandomName();
+ vector<Value> params;
+ params.emplace_back(file_glob);
+ named_parameter_map_t named_parameters({{"binary_as_string", Value::BOOLEAN(binary_as_string)},
+                                         {"file_row_number", Value::BOOLEAN(file_row_number)},
+                                         {"filename", Value::BOOLEAN(filename)},
+                                         {"hive_partitioning", Value::BOOLEAN(hive_partitioning)},
+                                         {"union_by_name", Value::BOOLEAN(union_by_name)}});
+ if (!py::none().is(compression)) {
+  if (!py::isinstance<py::str>(compression)) {
+   throw InvalidInputException("from_parquet only accepts 'compression' as a string");
+  }
+  named_parameters["compression"] = Value(py::str(compression));
+ }
+ return make_uniq<DuckDBPyRelation>(
+     connection->TableFunction("parquet_scan", params, named_parameters)->Alias(name));
+}
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromParquets(const vector<string> &file_globs, bool binary_as_string,
+                                                              bool file_row_number, bool filename,
+                                                              bool hive_partitioning, bool union_by_name,
+                                                              const py::object &compression) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ string name = "parquet_" + StringUtil::GenerateRandomName();
+ vector<Value> params;
+ auto file_globs_as_value = vector<Value>();
+ for (const auto &file : file_globs) {
+  file_globs_as_value.emplace_back(file);
+ }
+ params.emplace_back(Value::LIST(file_globs_as_value));
+ named_parameter_map_t named_parameters({{"binary_as_string", Value::BOOLEAN(binary_as_string)},
+                                         {"file_row_number", Value::BOOLEAN(file_row_number)},
+                                         {"filename", Value::BOOLEAN(filename)},
+                                         {"hive_partitioning", Value::BOOLEAN(hive_partitioning)},
+                                         {"union_by_name", Value::BOOLEAN(union_by_name)}});
+ if (!py::none().is(compression)) {
+  if (!py::isinstance<py::str>(compression)) {
+   throw InvalidInputException("from_parquet only accepts 'compression' as a string");
+  }
+  named_parameters["compression"] = Value(py::str(compression));
+ }
+ return make_uniq<DuckDBPyRelation>(
+     connection->TableFunction("parquet_scan", params, named_parameters)->Alias(name));
+}
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromArrow(py::object &arrow_object) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ py::gil_scoped_acquire acquire;
+ string name = "arrow_object_" + StringUtil::GenerateRandomName();
+ if (!IsAcceptedArrowObject(arrow_object)) {
+  auto py_object_type = string(py::str(arrow_object.get_type().attr("__name__")));
+  throw InvalidInputException("Python Object Type %s is not an accepted Arrow Object.", py_object_type);
+ }
+ auto stream_factory =
+     make_uniq<PythonTableArrowArrayStreamFactory>(arrow_object.ptr(), connection->context->config);
+ auto stream_factory_produce = PythonTableArrowArrayStreamFactory::Produce;
+ auto stream_factory_get_schema = PythonTableArrowArrayStreamFactory::GetSchema;
+ auto rel = connection
+                ->TableFunction("arrow_scan", {Value::POINTER((uintptr_t)stream_factory.get()),
+                                               Value::POINTER((uintptr_t)stream_factory_produce),
+                                               Value::POINTER((uintptr_t)stream_factory_get_schema)})
+                ->Alias(name);
+ rel->extra_dependencies =
+     make_uniq<PythonDependencies>(make_uniq<RegisteredArrow>(std::move(stream_factory), arrow_object));
+ return make_uniq<DuckDBPyRelation>(std::move(rel));
+}
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromSubstrait(py::bytes &proto) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ string name = "substrait_" + StringUtil::GenerateRandomName();
+ vector<Value> params;
+ params.emplace_back(Value::BLOB_RAW(proto));
+ return make_uniq<DuckDBPyRelation>(connection->TableFunction("from_substrait", params)->Alias(name));
+}
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::GetSubstrait(const string &query, bool enable_optimizer) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ vector<Value> params;
+ params.emplace_back(query);
+ named_parameter_map_t named_parameters({{"enable_optimizer", Value::BOOLEAN(enable_optimizer)}});
+ return make_uniq<DuckDBPyRelation>(
+     connection->TableFunction("get_substrait", params, named_parameters)->Alias(query));
+}
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::GetSubstraitJSON(const string &query, bool enable_optimizer) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ vector<Value> params;
+ params.emplace_back(query);
+ named_parameter_map_t named_parameters({{"enable_optimizer", Value::BOOLEAN(enable_optimizer)}});
+ return make_uniq<DuckDBPyRelation>(
+     connection->TableFunction("get_substrait_json", params, named_parameters)->Alias(query));
+}
+unique_ptr<DuckDBPyRelation> DuckDBPyConnection::FromSubstraitJSON(const string &json) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ string name = "from_substrait_" + StringUtil::GenerateRandomName();
+ vector<Value> params;
+ params.emplace_back(json);
+ return make_uniq<DuckDBPyRelation>(connection->TableFunction("from_substrait_json", params)->Alias(name));
+}
+unordered_set<string> DuckDBPyConnection::GetTableNames(const string &query) {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ return connection->GetTableNames(query);
+}
+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::UnregisterPythonObject(const string &name) {
+ connection->context->external_dependencies.erase(name);
+ temporary_views.erase(name);
+ py::gil_scoped_release release;
+ if (connection) {
+  connection->Query("DROP VIEW \"" + name + "\"");
+ }
+ return shared_from_this();
@@ -12955,2 +899,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- default:
-  throw NotImplementedException("Unsupported pandas type");
+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Begin() {
+ Execute("BEGIN TRANSACTION");
+ return shared_from_this();
@@ -12957,0 +903,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Commit() {
+ if (connection->context->transaction.IsAutoCommit()) {
+  return shared_from_this();
@@ -12959,173 +907,2 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
-  }
-  break;
- }
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
-  }
-  break;
- }
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
-  }
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
-    }
-   }
-  }
-  break;
- }
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
+ Execute("COMMIT");
+ return shared_from_this();
@@ -13133 +910,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Rollback() {
+ Execute("ROLLBACK");
+ return shared_from_this();
@@ -13135,2 +914,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- default:
-  throw NotImplementedException("Unsupported pandas type");
+Optional<py::list> DuckDBPyConnection::GetDescription() {
+ if (!result) {
+  return py::none();
@@ -13137,0 +918 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ return result->Description();
@@ -13139,50 +920,6 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vector &out) {
- D_ASSERT(bind_data.numpy_col->Backend() == PandasColumnBackend::NUMPY);
- auto &numpy_col = (PandasNumpyColumn &)*bind_data.numpy_col;
- auto &array = numpy_col.array;
- switch (bind_data.numpy_type) {
- case NumpyNullableType::BOOL:
-  ScanPandasMasked<bool>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_8:
-  ScanPandasMasked<uint8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_16:
-  ScanPandasMasked<uint16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_32:
-  ScanPandasMasked<uint32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::UINT_64:
-  ScanPandasMasked<uint64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_8:
-  ScanPandasMasked<int8_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_16:
-  ScanPandasMasked<int16_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_32:
-  ScanPandasMasked<int32_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::INT_64:
-  ScanPandasMasked<int64_t>(bind_data, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_32:
-  ScanPandasFpColumn<float>((float *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::FLOAT_64:
-  ScanPandasFpColumn<double>((double *)array.data(), numpy_col.stride, count, offset, out);
-  break;
- case NumpyNullableType::DATETIME:
- case NumpyNullableType::DATETIME_TZ: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<timestamp_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   tgt_ptr[row] = Timestamp::FromEpochNanoSeconds(src_ptr[source_idx]);
+void DuckDBPyConnection::Close() {
+ result = nullptr;
+ connection = nullptr;
+ database = nullptr;
+ for (auto &cur : cursors) {
+  cur->Close();
@@ -13190 +927,17 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ cursors.clear();
+}
+void DuckDBPyConnection::InstallExtension(const string &extension, bool force_install) {
+ ExtensionHelper::InstallExtension(*connection->context, extension, force_install);
+}
+void DuckDBPyConnection::LoadExtension(const string &extension) {
+ ExtensionHelper::LoadExternalExtension(*connection->context, extension);
+}
+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Cursor() {
+ if (!connection) {
+  throw ConnectionException("Connection has already been closed");
+ }
+ auto res = make_shared<DuckDBPyConnection>();
+ res->database = database;
+ res->connection = make_uniq<Connection>(*res->database);
+ cursors.push_back(res);
+ return res;
@@ -13192,20 +945,185 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::TIMEDELTA: {
-  auto src_ptr = (int64_t *)array.data();
-  auto tgt_ptr = FlatVector::GetData<interval_t>(out);
-  auto &mask = FlatVector::Validity(out);
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = offset + row;
-   if (src_ptr[source_idx] <= NumericLimits<int64_t>::Minimum()) {
-    mask.SetInvalid(row);
-    continue;
-   }
-   int64_t micro = src_ptr[source_idx] / 1000;
-   int64_t days = micro / Interval::MICROS_PER_DAY;
-   micro = micro % Interval::MICROS_PER_DAY;
-   int64_t months = days / Interval::DAYS_PER_MONTH;
-   days = days % Interval::DAYS_PER_MONTH;
-   interval_t interval;
-   interval.months = months;
-   interval.days = days;
-   interval.micros = micro;
-   tgt_ptr[row] = interval;
+Optional<py::tuple> DuckDBPyConnection::FetchOne() {
+ if (!result) {
+  throw InvalidInputException("No open result set");
+ }
+ return result->FetchOne();
+}
+py::list DuckDBPyConnection::FetchMany(idx_t size) {
+ if (!result) {
+  throw InvalidInputException("No open result set");
+ }
+ return result->FetchMany(size);
+}
+py::list DuckDBPyConnection::FetchAll() {
+ if (!result) {
+  throw InvalidInputException("No open result set");
+ }
+ return result->FetchAll();
+}
+py::dict DuckDBPyConnection::FetchNumpy() {
+ if (!result) {
+  throw InvalidInputException("No open result set");
+ }
+ return result->FetchNumpyInternal();
+}
+DataFrame DuckDBPyConnection::FetchDF(bool date_as_object) {
+ if (!result) {
+  throw InvalidInputException("No open result set");
+ }
+ return result->FetchDF(date_as_object);
+}
+DataFrame DuckDBPyConnection::FetchDFChunk(const idx_t vectors_per_chunk, bool date_as_object) const {
+ if (!result) {
+  throw InvalidInputException("No open result set");
+ }
+ return result->FetchDFChunk(vectors_per_chunk, date_as_object);
+}
+duckdb::pyarrow::Table DuckDBPyConnection::FetchArrow(idx_t chunk_size) {
+ if (!result) {
+  throw InvalidInputException("No open result set");
+ }
+ return result->ToArrowTable(chunk_size);
+}
+py::dict DuckDBPyConnection::FetchPyTorch() {
+ if (!result) {
+  throw InvalidInputException("No open result set");
+ }
+ return result->FetchPyTorch();
+}
+py::dict DuckDBPyConnection::FetchTF() {
+ if (!result) {
+  throw InvalidInputException("No open result set");
+ }
+ return result->FetchTF();
+}
+PolarsDataFrame DuckDBPyConnection::FetchPolars(idx_t chunk_size) {
+ auto arrow = FetchArrow(chunk_size);
+ return py::cast<PolarsDataFrame>(py::module::import("polars").attr("DataFrame")(arrow));
+}
+duckdb::pyarrow::RecordBatchReader DuckDBPyConnection::FetchRecordBatchReader(const idx_t chunk_size) const {
+ if (!result) {
+  throw InvalidInputException("No open result set");
+ }
+ return result->FetchRecordBatchReader(chunk_size);
+}
+static void CreateArrowScan(py::object entry, TableFunctionRef &table_function,
+                            vector<unique_ptr<ParsedExpression>> &children, ClientConfig &config) {
+ string name = "arrow_" + StringUtil::GenerateRandomName();
+ auto stream_factory = make_uniq<PythonTableArrowArrayStreamFactory>(entry.ptr(), config);
+ auto stream_factory_produce = PythonTableArrowArrayStreamFactory::Produce;
+ auto stream_factory_get_schema = PythonTableArrowArrayStreamFactory::GetSchema;
+ children.push_back(make_uniq<ConstantExpression>(Value::POINTER((uintptr_t)stream_factory.get())));
+ children.push_back(make_uniq<ConstantExpression>(Value::POINTER((uintptr_t)stream_factory_produce)));
+ children.push_back(make_uniq<ConstantExpression>(Value::POINTER((uintptr_t)stream_factory_get_schema)));
+ table_function.function = make_uniq<FunctionExpression>("arrow_scan", std::move(children));
+ table_function.external_dependency =
+     make_uniq<PythonDependencies>(make_uniq<RegisteredArrow>(std::move(stream_factory), entry));
+}
+static unique_ptr<TableRef> TryReplacement(py::dict &dict, py::str &table_name, ClientConfig &config,
+                                           py::object &current_frame) {
+ if (!dict.contains(table_name)) {
+  return nullptr;
+ }
+ auto entry = dict[table_name];
+ auto table_function = make_uniq<TableFunctionRef>();
+ vector<unique_ptr<ParsedExpression>> children;
+ if (DuckDBPyConnection::IsPandasDataframe(entry)) {
+  if (IsArrowBackedDataFrame(entry)) {
+   auto table = ArrowTableFromDataframe(entry);
+   CreateArrowScan(table, *table_function, children, config);
+  } else {
+   string name = "df_" + StringUtil::GenerateRandomName();
+   auto new_df = PandasScanFunction::PandasReplaceCopiedNames(entry);
+   children.push_back(make_uniq<ConstantExpression>(Value::POINTER((uintptr_t)new_df.ptr())));
+   table_function->function = make_uniq<FunctionExpression>("pandas_scan", std::move(children));
+   table_function->external_dependency =
+       make_uniq<PythonDependencies>(make_uniq<RegisteredObject>(entry), make_uniq<RegisteredObject>(new_df));
+  }
+ } else if (DuckDBPyConnection::IsAcceptedArrowObject(entry)) {
+  CreateArrowScan(entry, *table_function, children, config);
+ } else if (DuckDBPyRelation::IsRelation(entry)) {
+  auto pyrel = py::cast<DuckDBPyRelation *>(entry);
+  auto select = make_uniq<SelectStatement>();
+  select->node = pyrel->GetRel().GetQueryNode();
+  auto subquery = make_uniq<SubqueryRef>(std::move(select));
+  return std::move(subquery);
+ } else if (PolarsDataFrame::IsDataFrame(entry)) {
+  auto arrow_dataset = entry.attr("to_arrow")();
+  CreateArrowScan(arrow_dataset, *table_function, children, config);
+ } else if (PolarsDataFrame::IsLazyFrame(entry)) {
+  auto materialized = entry.attr("collect")();
+  auto arrow_dataset = materialized.attr("to_arrow")();
+  CreateArrowScan(arrow_dataset, *table_function, children, config);
+ } else {
+  std::string location = py::cast<py::str>(current_frame.attr("f_code").attr("co_filename"));
+  location += ":";
+  location += py::cast<py::str>(current_frame.attr("f_lineno"));
+  std::string cpp_table_name = table_name;
+  auto py_object_type = string(py::str(entry.get_type().attr("__name__")));
+  throw InvalidInputException(
+      "Python Object \"%s\" of type \"%s\" found on line \"%s\" not suitable for replacement scans.\nMake sure "
+      "that \"%s\" is either a pandas.DataFrame, duckdb.DuckDBPyRelation, pyarrow Table, Dataset, "
+      "RecordBatchReader, or Scanner",
+      cpp_table_name, py_object_type, location, cpp_table_name);
+ }
+ return std::move(table_function);
+}
+static unique_ptr<TableRef> ScanReplacement(ClientContext &context, const string &table_name,
+                                            ReplacementScanData *data) {
+ py::gil_scoped_acquire acquire;
+ auto py_table_name = py::str(table_name);
+ auto current_frame = py::module::import("inspect").attr("currentframe")();
+ while (hasattr(current_frame, "f_locals")) {
+  auto local_dict = py::reinterpret_borrow<py::dict>(current_frame.attr("f_locals"));
+  if (local_dict) {
+   auto result = TryReplacement(local_dict, py_table_name, context.config, current_frame);
+   if (result) {
+    return result;
+   }
+  }
+  auto global_dict = py::reinterpret_borrow<py::dict>(current_frame.attr("f_globals"));
+  if (global_dict) {
+   auto result = TryReplacement(global_dict, py_table_name, context.config, current_frame);
+   if (result) {
+    return result;
+   }
+  }
+  current_frame = current_frame.attr("f_back");
+ }
+ return nullptr;
+}
+unordered_map<string, string> TransformPyConfigDict(const py::dict &py_config_dict) {
+ unordered_map<string, string> config_dict;
+ for (auto &kv : py_config_dict) {
+  auto key = py::str(kv.first);
+  auto val = py::str(kv.second);
+  config_dict[key] = val;
+ }
+ return config_dict;
+}
+void CreateNewInstance(DuckDBPyConnection &res, const string &database, DBConfig &config) {
+ bool cache_instance = database != ":memory:" && !database.empty();
+ res.database = instance_cache.CreateInstance(database, config, cache_instance);
+ res.connection = make_uniq<Connection>(*res.database);
+ auto &context = *res.connection->context;
+ PandasScanFunction scan_fun;
+ CreateTableFunctionInfo scan_info(scan_fun);
+ MapFunction map_fun;
+ CreateTableFunctionInfo map_info(map_fun);
+ auto &catalog = Catalog::GetSystemCatalog(context);
+ context.transaction.BeginTransaction();
+ catalog.CreateTableFunction(context, &scan_info);
+ catalog.CreateTableFunction(context, &map_info);
+ context.transaction.Commit();
+ auto &db_config = res.database->instance->config;
+ db_config.AddExtensionOption("pandas_analyze_sample",
+                              "The maximum number of rows to sample when analyzing a pandas object column.",
+                              LogicalType::UBIGINT, Value::UBIGINT(1000));
+ if (db_config.options.enable_external_access) {
+  db_config.replacement_scans.emplace_back(ScanReplacement);
+ }
+}
+static bool HasJupyterProgressBarDependencies() {
+ auto &import_cache = *DuckDBPyConnection::ImportCache();
+ if (!import_cache.ipywidgets().IsLoaded()) {
+  return false;
@@ -13213 +1131 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ return true;
@@ -13215,4 +1133,79 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::OBJECT: {
-  auto src_ptr = (PyObject **)array.data();
-  if (out.GetType().id() != LogicalTypeId::VARCHAR) {
-   return ScanPandasObjectColumn(bind_data, src_ptr, count, offset, out);
+static void SetDefaultConfigArguments(ClientContext &context) {
+ if (!DuckDBPyConnection::IsInteractive()) {
+  return;
+ }
+ auto &config = ClientConfig::GetConfig(context);
+ config.enable_progress_bar = true;
+ if (!DuckDBPyConnection::IsJupyter()) {
+  return;
+ }
+ if (!HasJupyterProgressBarDependencies()) {
+  config.system_progress_bar_disable_reason =
+      "required package 'ipywidgets' is missing, which is needed to render progress bars in Jupyter";
+  config.enable_progress_bar = false;
+  return;
+ }
+ context.config.display_create_func = JupyterProgressBarDisplay::Create;
+}
+static shared_ptr<DuckDBPyConnection> FetchOrCreateInstance(const string &database, DBConfig &config) {
+ auto res = make_shared<DuckDBPyConnection>();
+ res->database = instance_cache.GetInstance(database, config);
+ if (!res->database) {
+  CreateNewInstance(*res, database, config);
+  return res;
+ }
+ res->connection = make_uniq<Connection>(*res->database);
+ return res;
+}
+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Connect(const string &database, bool read_only,
+                                                           const py::dict &config_options) {
+ auto config_dict = TransformPyConfigDict(config_options);
+ DBConfig config(config_dict, read_only);
+ auto res = FetchOrCreateInstance(database, config);
+ auto &client_context = *res->connection->context;
+ SetDefaultConfigArguments(client_context);
+ return res;
+}
+vector<Value> DuckDBPyConnection::TransformPythonParamList(const py::handle &params) {
+ vector<Value> args;
+ args.reserve(py::len(params));
+ for (auto param : params) {
+  args.emplace_back(TransformPythonValue(param, LogicalType::UNKNOWN, false));
+ }
+ return args;
+}
+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::DefaultConnection() {
+ if (!default_connection) {
+  py::dict config_dict;
+  default_connection = DuckDBPyConnection::Connect(":memory:", false, config_dict);
+ }
+ return default_connection;
+}
+PythonImportCache *DuckDBPyConnection::ImportCache() {
+ if (!import_cache) {
+  import_cache = make_shared<PythonImportCache>();
+ }
+ return import_cache.get();
+}
+ModifiedMemoryFileSystem &DuckDBPyConnection::GetObjectFileSystem() {
+ if (!internal_object_filesystem) {
+  D_ASSERT(!FileSystemIsRegistered("DUCKDB_INTERNAL_OBJECTSTORE"));
+  auto &import_cache_py = *ImportCache();
+  internal_object_filesystem =
+      make_shared<ModifiedMemoryFileSystem>(import_cache_py.pyduckdb().filesystem.modified_memory_filesystem()());
+  auto &abstract_fs = (AbstractFileSystem &)*internal_object_filesystem;
+  RegisterFilesystem(abstract_fs);
+ }
+ return *internal_object_filesystem;
+}
+bool DuckDBPyConnection::IsInteractive() {
+ return DuckDBPyConnection::environment != PythonEnvironmentType::NORMAL;
+}
+shared_ptr<DuckDBPyConnection> DuckDBPyConnection::Enter() {
+ return shared_from_this();
+}
+bool DuckDBPyConnection::Exit(DuckDBPyConnection &self, const py::object &exc_type, const py::object &exc,
+                              const py::object &traceback) {
+ self.Close();
+ if (exc_type.ptr() != Py_None) {
+  return false;
@@ -13220,74 +1213 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  auto tgt_ptr = FlatVector::GetData<string_t>(out);
-  auto &out_mask = FlatVector::Validity(out);
-  unique_ptr<PythonGILWrapper> gil;
-  auto &import_cache = *DuckDBPyConnection::ImportCache();
-  auto stride = numpy_col.stride;
-  for (idx_t row = 0; row < count; row++) {
-   auto source_idx = stride / sizeof(PyObject *) * (row + offset);
-   PyObject *val = src_ptr[source_idx];
-   if (bind_data.numpy_type == NumpyNullableType::OBJECT && !PyUnicode_CheckExact(val)) {
-    if (val == Py_None) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (import_cache.pandas().libs.NAType.IsLoaded()) {
-     auto val_type = Py_TYPE(val);
-     auto na_type = (PyTypeObject *)import_cache.pandas().libs.NAType().ptr();
-     if (val_type == na_type) {
-      out_mask.SetInvalid(row);
-      continue;
-     }
-    }
-    if (py::isinstance<py::float_>(val) && std::isnan(PyFloat_AsDouble(val))) {
-     out_mask.SetInvalid(row);
-     continue;
-    }
-    if (!py::isinstance<py::str>(val)) {
-     if (!gil) {
-      gil = bind_data.object_str_val.GetLock();
-     }
-     bind_data.object_str_val.AssignInternal<PyObject>(
-         [](py::str &obj, PyObject &new_val) {
-          py::handle object_handle = &new_val;
-          obj = py::str(object_handle);
-         },
-         *val, *gil);
-     val = (PyObject *)bind_data.object_str_val.GetPointerTop()->ptr();
-    }
-   }
-   if (!PyUnicode_CheckExact(val)) {
-    out_mask.SetInvalid(row);
-    continue;
-   }
-   if (PyUnicode_IS_COMPACT_ASCII(val)) {
-    tgt_ptr[row] = string_t((const char *)PyUnicode_DATA(val), PyUnicode_GET_LENGTH(val));
-   } else {
-    auto ascii_obj = (PyASCIIObject *)val;
-    auto unicode_obj = (PyCompactUnicodeObject *)val;
-    if (unicode_obj->utf8) {
-     tgt_ptr[row] = string_t((const char *)unicode_obj->utf8, unicode_obj->utf8_length);
-    } else if (PyUnicode_IS_COMPACT(unicode_obj) && !PyUnicode_IS_ASCII(unicode_obj)) {
-     auto kind = PyUnicode_KIND(val);
-     switch (kind) {
-     case PyUnicode_1BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS1>(PyUnicode_1BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_2BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS2>(PyUnicode_2BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     case PyUnicode_4BYTE_KIND:
-      tgt_ptr[row] =
-          DecodePythonUnicode<Py_UCS4>(PyUnicode_4BYTE_DATA(val), PyUnicode_GET_LENGTH(val), out);
-      break;
-     default:
-      throw NotImplementedException(
-          "Unsupported typekind constant %d for Python Unicode Compact decode", kind);
-     }
-    } else if (ascii_obj->state.kind == PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode not ready legacy string");
-    } else if (!PyUnicode_IS_COMPACT(unicode_obj) && ascii_obj->state.kind != PyUnicode_WCHAR_KIND) {
-     throw InvalidInputException("Unsupported: decode ready legacy string");
-    } else {
-     throw InvalidInputException("Unsupported string type: no clue what this string is");
+ return true;
@@ -13294,0 +1215,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+void DuckDBPyConnection::Cleanup() {
+ default_connection.reset();
+ import_cache.reset();
@@ -13295,0 +1219,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+bool DuckDBPyConnection::IsPandasDataframe(const py::object &object) {
+ if (!ModuleIsLoaded<PandasCacheItem>()) {
+  return false;
@@ -13297 +1223,2 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ auto &import_cache_py = *DuckDBPyConnection::ImportCache();
+ return import_cache_py.pandas().DataFrame.IsInstance(object);
@@ -13299,13 +1226,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- case NumpyNullableType::CATEGORY: {
-  switch (out.GetType().InternalType()) {
-  case PhysicalType::UINT8:
-   ScanPandasCategory<uint8_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT16:
-   ScanPandasCategory<uint16_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  case PhysicalType::UINT32:
-   ScanPandasCategory<uint32_t>(array, count, offset, out, bind_data.internal_categorical_type);
-   break;
-  default:
-   throw InternalException("Invalid Physical Type for ENUMs");
+bool DuckDBPyConnection::IsPolarsDataframe(const py::object &object) {
+ if (!ModuleIsLoaded<PolarsCacheItem>()) {
+  return false;
@@ -13313 +1230,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
-  break;
+ auto &import_cache_py = *DuckDBPyConnection::ImportCache();
+ return import_cache_py.polars().DataFrame.IsInstance(object) ||
+        import_cache_py.polars().LazyFrame.IsInstance(object);
@@ -13315,2 +1234,3 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
- default:
-  throw NotImplementedException("Unsupported pandas type");
+bool DuckDBPyConnection::IsAcceptedArrowObject(const py::object &object) {
+ if (!ModuleIsLoaded<ArrowCacheItem>()) {
+  return false;
@@ -13317,0 +1238,5 @@ void Numpy::Scan(PandasColumnBindData &bind_data, idx_t count, idx_t offset, Vec
+ auto &import_cache_py = *DuckDBPyConnection::ImportCache();
+ return import_cache_py.arrow().lib.Table.IsInstance(object) ||
+        import_cache_py.arrow().lib.RecordBatchReader.IsInstance(object) ||
+        import_cache_py.arrow().dataset.Dataset.IsInstance(object) ||
+        import_cache_py.arrow().dataset.Scanner.IsInstance(object);
