diff --git a/home/whalien/codebase/cpp/mergebot/eva/output/rocksdb/ee4b9966-5aa81f04-45ad75db/tools@db_stress.no_comments_mergebot.cc b/home/whalien/codebase/cpp/mergebot/eva/output/rocksdb/ee4b9966-5aa81f04-45ad75db/tools@db_stress.no_comments_merged.cc
index 85ed301..5abbd91 100644
--- a/home/whalien/codebase/cpp/mergebot/eva/output/rocksdb/ee4b9966-5aa81f04-45ad75db/tools@db_stress.no_comments_mergebot.cc
+++ b/home/whalien/codebase/cpp/mergebot/eva/output/rocksdb/ee4b9966-5aa81f04-45ad75db/tools@db_stress.no_comments_merged.cc
@@ -13,0 +14 @@
+#include "rocksdb/statistics.h"
@@ -28 +29,3 @@ static bool ValidateUint32Range(const char* flagname, uint64_t value) {
-    fprintf(stderr, "Invalid value for --%s: %lu, overflow\n", flagname,
+    fprintf(stderr,
+            "Invalid value for --%s: %lu, overflow\n",
+            flagname,
@@ -34,3 +37,84 @@ static bool ValidateUint32Range(const char* flagname, uint64_t value) {
-static const bool FLAGS_purge_redundant_percent_dummy __attribute__((unused)) =
-    google::RegisterFlagValidator(&FLAGS_purge_redundant_percent,
-                                  &ValidateInt32Percent);
+DEFINE_uint64(seed, 2341234, "Seed for PRNG");
+static const bool FLAGS_seed_dummy __attribute__((unused)) =
+    google::RegisterFlagValidator(&FLAGS_seed, &ValidateUint32Range);
+DEFINE_int64(max_key, 1 * KB* KB,
+             "Max number of key/values to place in database");
+DEFINE_int32(column_families, 10, "Number of column families");
+DEFINE_bool(test_batches_snapshots, false,
+            "If set, the test uses MultiGet(), MultiPut() and MultiDelete()"
+            " which read/write/delete multiple keys in a batch. In this mode,"
+            " we do not verify db content by comparing the content with the "
+            "pre-allocated array. Instead, we do partial verification inside"
+            " MultiGet() by checking various values in a batch. Benefit of"
+            " this mode:\n"
+            "\t(a) No need to acquire mutexes during writes (less cache "
+            "flushes in multi-core leading to speed up)\n"
+            "\t(b) No long validation at the end (more speed up)\n"
+            "\t(c) Test snapshot and atomicity of batch writes");
+DEFINE_int32(threads, 32, "Number of concurrent threads to run.");
+DEFINE_int32(ttl, -1,
+             "Opens the db with this ttl value if this is not -1. "
+             "Carefully specify a large value such that verifications on "
+             "deleted values don't fail");
+DEFINE_int32(value_size_mult, 8,
+             "Size of value will be this number times rand_int(1,3) bytes");
+DEFINE_bool(verify_before_write, false, "Verify before write");
+DEFINE_bool(histogram, false, "Print histogram of operation timings");
+DEFINE_bool(destroy_db_initially, true,
+            "Destroys the database dir before start if this is true");
+DEFINE_bool (verbose, false, "Verbose");
+DEFINE_int32(write_buffer_size, rocksdb::Options().write_buffer_size,
+             "Number of bytes to buffer in memtable before compacting");
+DEFINE_int32(max_write_buffer_number,
+             rocksdb::Options().max_write_buffer_number,
+             "The number of in-memory memtables. "
+             "Each memtable is of size FLAGS_write_buffer_size.");
+DEFINE_int32(min_write_buffer_number_to_merge,
+             rocksdb::Options().min_write_buffer_number_to_merge,
+             "The minimum number of write buffers that will be merged together "
+             "before writing to storage. This is cheap because it is an "
+             "in-memory merge. If this feature is not enabled, then all these "
+             "write buffers are flushed to L0 as separate files and this "
+             "increases read amplification because a get request has to check "
+             "in all of these files. Also, an in-memory merge may result in "
+             "writing less data to storage if there are duplicate records in"
+             " each of these individual write buffers.");
+DEFINE_int32(open_files, rocksdb::Options().max_open_files,
+             "Maximum number of files to keep open at the same time "
+             "(use default if == 0)");
+DEFINE_int64(compressed_cache_size, -1,
+             "Number of bytes to use as a cache of compressed data."
+             " Negative means use default settings.");
+DEFINE_int32(compaction_style, rocksdb::Options().compaction_style, "");
+DEFINE_int32(level0_file_num_compaction_trigger,
+             rocksdb::Options().level0_file_num_compaction_trigger,
+             "Level0 compaction start trigger");
+DEFINE_int32(level0_slowdown_writes_trigger,
+             rocksdb::Options().level0_slowdown_writes_trigger,
+             "Number of files in level-0 that will slow down writes");
+DEFINE_int32(level0_stop_writes_trigger,
+             rocksdb::Options().level0_stop_writes_trigger,
+             "Number of files in level-0 that will trigger put stop.");
+DEFINE_int32(block_size, rocksdb::Options().block_size,
+             "Number of bytes in a block.");
+DEFINE_int32(max_background_compactions,
+             rocksdb::Options().max_background_compactions,
+             "The maximum number of concurrent background compactions "
+             "that can occur in parallel.");
+DEFINE_int32(max_background_flushes, rocksdb::Options().max_background_flushes,
+             "The maximum number of concurrent background flushes "
+             "that can occur in parallel.");
+DEFINE_int32(universal_size_ratio, 0, "The ratio of file sizes that trigger"
+             " compaction in universal style");
+DEFINE_int32(universal_min_merge_width, 0, "The minimum number of files to "
+             "compact in universal style compaction");
+DEFINE_int32(universal_max_merge_width, 0, "The max number of files to compact"
+             " in universal style compaction");
+DEFINE_int32(universal_max_size_amplification_percent, 0,
+             "The max size amplification for universal style compaction");
+DEFINE_int32(clear_column_family_one_in, 1000000,
+             "With a chance of 1/N, delete a column family and then recreate "
+             "it again. If N == 0, never drop/create column families. "
+             "When test_batches_snapshots is true, this flag has no effect");
+DEFINE_int64(cache_size, 2 * KB * KB * KB,
+             "Number of bytes to use as a cache of uncompressed data.");
@@ -39,2 +123,2 @@ static bool ValidateInt32Positive(const char* flagname, int32_t value) {
-    fprintf(stderr, "Invalid value for --%s: %d, must be >=0\n", flagname,
-            value);
+    fprintf(stderr, "Invalid value for --%s: %d, must be >=0\n",
+            flagname, value);
@@ -44,0 +129,10 @@ static bool ValidateInt32Positive(const char* flagname, int32_t value) {
+DEFINE_int32(reopen, 10, "Number of times database reopens");
+static const bool FLAGS_reopen_dummy __attribute__((unused)) =
+    google::RegisterFlagValidator(&FLAGS_reopen, &ValidateInt32Positive);
+DEFINE_int32(bloom_bits, 10, "Bloom filter bits per key. "
+             "Negative means use default settings.");
+DEFINE_string(db, "", "Use the db with the following name.");
+DEFINE_bool(verify_checksum, false,
+            "Verify checksum for every block read from storage");
+DEFINE_bool(mmap_read, rocksdb::EnvOptions().use_mmap_reads,
+            "Allow reads to occur via mmap-ing files");
@@ -45,0 +140,11 @@ static std::shared_ptr<rocksdb::Statistics> dbstats;
+DEFINE_bool(statistics, false, "Create database statistics");
+DEFINE_bool(sync, false, "Sync all writes to disk");
+DEFINE_bool(disable_data_sync, false,
+            "If true, do not wait until data is synced to disk.");
+DEFINE_bool(use_fsync, false, "If true, issue fsync instead of fdatasync");
+DEFINE_int32(kill_random_test, 0,
+             "If non-zero, kill at various points in source code with "
+             "probability 1/this");
+static const bool FLAGS_kill_random_test_dummy __attribute__((unused)) =
+    google::RegisterFlagValidator(&FLAGS_kill_random_test,
+                                  &ValidateInt32Positive);
@@ -46,0 +152,8 @@ extern int rocksdb_kill_odds;
+DEFINE_bool(disable_wal, false, "If true, do not write WAL for write.");
+DEFINE_int32(target_file_size_base, 64 * KB,
+             "Target level-1 file size for compaction");
+DEFINE_int32(target_file_size_multiplier, 1,
+             "A multiplier to compute targe level-N file size (N >= 2)");
+DEFINE_uint64(max_bytes_for_level_base, 256 * KB, "Max bytes for level-1");
+DEFINE_int32(max_bytes_for_level_multiplier, 2,
+             "A multiplier to compute max bytes for level-N (N >= 2)");
@@ -49,2 +162,2 @@ static bool ValidateInt32Percent(const char* flagname, int32_t value) {
-    fprintf(stderr, "Invalid value for --%s: %d, 0<= pct <=100 \n", flagname,
-            value);
+    fprintf(stderr, "Invalid value for --%s: %d, 0<= pct <=100 \n",
+            flagname, value);
@@ -54,0 +168,26 @@ static bool ValidateInt32Percent(const char* flagname, int32_t value) {
+DEFINE_int32(readpercent, 10,
+             "Ratio of reads to total workload (expressed as a percentage)");
+static const bool FLAGS_readpercent_dummy __attribute__((unused)) =
+    google::RegisterFlagValidator(&FLAGS_readpercent, &ValidateInt32Percent);
+DEFINE_int32(prefixpercent, 20,
+             "Ratio of prefix iterators to total workload (expressed as a"
+             " percentage)");
+static const bool FLAGS_prefixpercent_dummy __attribute__((unused)) =
+    google::RegisterFlagValidator(&FLAGS_prefixpercent, &ValidateInt32Percent);
+DEFINE_int32(writepercent, 45,
+             " Ratio of deletes to total workload (expressed as a percentage)");
+static const bool FLAGS_writepercent_dummy __attribute__((unused)) =
+    google::RegisterFlagValidator(&FLAGS_writepercent, &ValidateInt32Percent);
+DEFINE_int32(delpercent, 15,
+             "Ratio of deletes to total workload (expressed as a percentage)");
+static const bool FLAGS_delpercent_dummy __attribute__((unused)) =
+    google::RegisterFlagValidator(&FLAGS_delpercent, &ValidateInt32Percent);
+DEFINE_int32(iterpercent, 10, "Ratio of iterations to total workload"
+             " (expressed as a percentage)");
+static const bool FLAGS_iterpercent_dummy __attribute__((unused)) =
+    google::RegisterFlagValidator(&FLAGS_iterpercent, &ValidateInt32Percent);
+DEFINE_uint64(num_iterations, 10, "Number of iterations per MultiIterate run");
+static const bool FLAGS_num_iterations_dummy __attribute__((unused)) =
+    google::RegisterFlagValidator(&FLAGS_num_iterations, &ValidateUint32Range);
+DEFINE_bool(disable_seek_compaction, false,
+            "Option to disable compation triggered by read.");
@@ -71,0 +211,2 @@ enum rocksdb::CompressionType StringToCompressionType(const char* ctype) {
+DEFINE_string(compression_type, "snappy",
+              "Algorithm to use to compress the database");
@@ -73,0 +215 @@ static enum rocksdb::CompressionType FLAGS_compression_type_e =
+DEFINE_string(hdfs, "", "Name of hdfs environment");
@@ -75 +217,20 @@ static rocksdb::Env* FLAGS_env = rocksdb::Env::Default();
-enum RepFactory { kSkipList, kHashSkipList, kVectorRep };
+DEFINE_uint64(ops_per_thread, 1200000, "Number of operations per thread.");
+static const bool FLAGS_ops_per_thread_dummy __attribute__((unused)) =
+    google::RegisterFlagValidator(&FLAGS_ops_per_thread, &ValidateUint32Range);
+DEFINE_uint64(log2_keys_per_lock, 2, "Log2 of number of keys per lock");
+static const bool FLAGS_log2_keys_per_lock_dummy __attribute__((unused)) =
+    google::RegisterFlagValidator(&FLAGS_log2_keys_per_lock,
+                                  &ValidateUint32Range);
+DEFINE_int32(purge_redundant_percent, 50,
+             "Percentage of times we want to purge redundant keys in memory "
+             "before flushing");
+static const bool FLAGS_purge_redundant_percent_dummy __attribute__((unused)) =
+    google::RegisterFlagValidator(&FLAGS_purge_redundant_percent,
+                                  &ValidateInt32Percent);
+DEFINE_bool(filter_deletes, false, "On true, deletes use KeyMayExist to drop"
+            " the delete if key not present");
+enum RepFactory {
+  kSkipList,
+  kHashSkipList,
+  kVectorRep
+};
@@ -87,0 +249 @@ static enum RepFactory FLAGS_rep_factory;
+DEFINE_string(memtablerep, "prefix_hash", "");
@@ -95,0 +258 @@ static bool ValidatePrefixSize(const char* flagname, int32_t value) {
+DEFINE_int32(prefix_size, 7, "Control the prefix size for HashSkipListRep");
@@ -97,0 +261,2 @@ static const bool FLAGS_prefix_size_dummy =
+DEFINE_bool(use_merge, false, "On true, replaces all writes with a Merge "
+            "that behaves like a Put");
@@ -182,14 +347,7 @@ class Stats {
-      if (next_report_ < 1000)
-        next_report_ += 100;
-      else if (next_report_ < 5000)
-        next_report_ += 500;
-      else if (next_report_ < 10000)
-        next_report_ += 1000;
-      else if (next_report_ < 50000)
-        next_report_ += 5000;
-      else if (next_report_ < 100000)
-        next_report_ += 10000;
-      else if (next_report_ < 500000)
-        next_report_ += 50000;
-      else
-        next_report_ += 100000;
+      if (next_report_ < 1000) next_report_ += 100;
+      else if (next_report_ < 5000) next_report_ += 500;
+      else if (next_report_ < 10000) next_report_ += 1000;
+      else if (next_report_ < 50000) next_report_ += 5000;
+      else if (next_report_ < 100000) next_report_ += 10000;
+      else if (next_report_ < 500000) next_report_ += 50000;
+      else next_report_ += 100000;
@@ -211,3 +369,9 @@ class Stats {
-  void AddIterations(int n) { iterations_ += n; }
-  void AddDeletes(int n) { deletes_ += n; }
-  void AddErrors(int n) { errors_ += n; }
+  void AddIterations(int n) {
+    iterations_ += n;
+  }
+  void AddDeletes(int n) {
+    deletes_ += n;
+  }
+  void AddErrors(int n) {
+    errors_ += n;
+  }
@@ -225,2 +389,2 @@ class Stats {
-    fprintf(stdout, "%.3f micros/op %ld ops/sec\n", seconds_ * 1e6 / done_,
-            (long)throughput);
+    fprintf(stdout, "%.3f micros/op %ld ops/sec\n",
+            seconds_ * 1e6 / done_, (long)throughput);
@@ -231,2 +395,2 @@ class Stats {
-    fprintf(stdout, "%-12s: %ld read and %ld found the key\n", "", gets_,
-            founds_);
+    fprintf(stdout, "%-12s: %ld read and %ld found the key\n", "",
+            gets_, founds_);
@@ -247,2 +411,2 @@ class SharedState {
-  explicitSharedState(StressTest* stress_test)
-      : cv_(&mu_),
+  explicit SharedState(StressTest* stress_test) :
+      cv_(&mu_),
@@ -279,17 +443,51 @@ class SharedState {
-  port::Mutex* GetMutex() { return &mu_; }
-  port::CondVar* GetCondVar() { return &cv_; }
-  StressTest* GetStressTest() const { return stress_test_; }
-  long GetMaxKey() const { return max_key_; }
-  uint32_t GetNumThreads() const { return num_threads_; }
-  void IncInitialized() { num_initialized_++; }
-  void IncOperated() { num_populated_++; }
-  void IncDone() { num_done_++; }
-  void IncVotedReopen() { vote_reopen_ = (vote_reopen_ + 1) % num_threads_; }
-  bool AllInitialized() const { return num_initialized_ >= num_threads_; }
-  bool AllOperated() const { return num_populated_ >= num_threads_; }
-  bool AllDone() const { return num_done_ >= num_threads_; }
-  bool AllVotedReopen() { return (vote_reopen_ == 0); }
-  void SetStart() { start_ = true; }
-  void SetStartVerify() { start_verify_ = true; }
-  bool Started() const { return start_; }
-  bool VerifyStarted() const { return start_verify_; }
+  port::Mutex* GetMutex() {
+    return &mu_;
+  }
+  port::CondVar* GetCondVar() {
+    return &cv_;
+  }
+  StressTest* GetStressTest() const {
+    return stress_test_;
+  }
+  long GetMaxKey() const {
+    return max_key_;
+  }
+  uint32_t GetNumThreads() const {
+    return num_threads_;
+  }
+  void IncInitialized() {
+    num_initialized_++;
+  }
+  void IncOperated() {
+    num_populated_++;
+  }
+  void IncDone() {
+    num_done_++;
+  }
+  void IncVotedReopen() {
+    vote_reopen_ = (vote_reopen_ + 1) % num_threads_;
+  }
+  bool AllInitialized() const {
+    return num_initialized_ >= num_threads_;
+  }
+  bool AllOperated() const {
+    return num_populated_ >= num_threads_;
+  }
+  bool AllDone() const {
+    return num_done_ >= num_threads_;
+  }
+  bool AllVotedReopen() {
+    return (vote_reopen_ == 0);
+  }
+  void SetStart() {
+    start_ = true;
+  }
+  void SetStartVerify() {
+    start_verify_ = true;
+  }
+  bool Started() const {
+    return start_;
+  }
+  bool VerifyStarted() const {
+    return start_verify_;
+  }
@@ -342,134 +540,3 @@ struct ThreadState {
-      : tid(index), rand(1000 + index + shared->GetSeed()), shared(shared) {}
-};
-}
-namespace {
-class Stats {
- private:
-  double start_;
-  double finish_;
-  double seconds_;
-  long done_;
-  long gets_;
-  long prefixes_;
-  long writes_;
-  long deletes_;
-  long iterator_size_sums_;
-  long founds_;
-  long iterations_;
-  long errors_;
-  int next_report_;
-  size_t bytes_;
-  double last_op_finish_;
-  HistogramImpl hist_;
- public:
-  Stats() {}
-  void Start() {
-    next_report_ = 100;
-    hist_.Clear();
-    done_ = 0;
-    gets_ = 0;
-    prefixes_ = 0;
-    writes_ = 0;
-    deletes_ = 0;
-    iterator_size_sums_ = 0;
-    founds_ = 0;
-    iterations_ = 0;
-    errors_ = 0;
-    bytes_ = 0;
-    seconds_ = 0;
-    start_ = FLAGS_env->NowMicros();
-    last_op_finish_ = start_;
-    finish_ = start_;
-  }
-  void Merge(const Stats& other) {
-    hist_.Merge(other.hist_);
-    done_ += other.done_;
-    gets_ += other.gets_;
-    prefixes_ += other.prefixes_;
-    writes_ += other.writes_;
-    deletes_ += other.deletes_;
-    iterator_size_sums_ += other.iterator_size_sums_;
-    founds_ += other.founds_;
-    iterations_ += other.iterations_;
-    errors_ += other.errors_;
-    bytes_ += other.bytes_;
-    seconds_ += other.seconds_;
-    if (other.start_ < start_) start_ = other.start_;
-    if (other.finish_ > finish_) finish_ = other.finish_;
-  }
-  void Stop() {
-    finish_ = FLAGS_env->NowMicros();
-    seconds_ = (finish_ - start_) * 1e-6;
-  }
-  void FinishedSingleOp() {
-    if (FLAGS_histogram) {
-      double now = FLAGS_env->NowMicros();
-      double micros = now - last_op_finish_;
-      hist_.Add(micros);
-      if (micros > 20000) {
-        fprintf(stdout, "long op: %.1f micros%30s\r", micros, "");
-      }
-      last_op_finish_ = now;
-    }
-    done_++;
-    if (done_ >= next_report_) {
-      if (next_report_ < 1000)
-        next_report_ += 100;
-      else if (next_report_ < 5000)
-        next_report_ += 500;
-      else if (next_report_ < 10000)
-        next_report_ += 1000;
-      else if (next_report_ < 50000)
-        next_report_ += 5000;
-      else if (next_report_ < 100000)
-        next_report_ += 10000;
-      else if (next_report_ < 500000)
-        next_report_ += 50000;
-      else
-        next_report_ += 100000;
-      fprintf(stdout, "... finished %ld ops%30s\r", done_, "");
-    }
-  }
-  void AddBytesForWrites(int nwrites, size_t nbytes) {
-    writes_ += nwrites;
-    bytes_ += nbytes;
-  }
-  void AddGets(int ngets, int nfounds) {
-    founds_ += nfounds;
-    gets_ += ngets;
-  }
-  void AddPrefixes(int nprefixes, int count) {
-    prefixes_ += nprefixes;
-    iterator_size_sums_ += count;
-  }
-  void AddIterations(int n) { iterations_ += n; }
-  void AddDeletes(int n) { deletes_ += n; }
-  void AddErrors(int n) { errors_ += n; }
-  void Report(const char* name) {
-    std::string extra;
-    if (bytes_ < 1 || done_ < 1) {
-      fprintf(stderr, "No writes or ops?\n");
-      return;
-    }
-    double elapsed = (finish_ - start_) * 1e-6;
-    double bytes_mb = bytes_ / 1048576.0;
-    double rate = bytes_mb / elapsed;
-    double throughput = (double)done_ / elapsed;
-    fprintf(stdout, "%-12s: ", name);
-    fprintf(stdout, "%.3f micros/op %ld ops/sec\n", seconds_ * 1e6 / done_,
-            (long)throughput);
-    fprintf(stdout, "%-12s: Wrote %.2f MB (%.2f MB/sec) (%ld%% of %ld ops)\n",
-            "", bytes_mb, rate, (100 * writes_) / done_, done_);
-    fprintf(stdout, "%-12s: Wrote %ld times\n", "", writes_);
-    fprintf(stdout, "%-12s: Deleted %ld times\n", "", deletes_);
-    fprintf(stdout, "%-12s: %ld read and %ld found the key\n", "", gets_,
-            founds_);
-    fprintf(stdout, "%-12s: Prefix scanned %ld times\n", "", prefixes_);
-    fprintf(stdout, "%-12s: Iterator size sum is %ld\n", "",
-            iterator_size_sums_);
-    fprintf(stdout, "%-12s: Iterated %ld times\n", "", iterations_);
-    fprintf(stdout, "%-12s: Got errors %ld times\n", "", errors_);
-    if (FLAGS_histogram) {
-      fprintf(stdout, "Microseconds per op:\n%s\n", hist_.ToString().c_str());
-    }
-    fflush(stdout);
+      : tid(index),
+        rand(1000 + index + shared->GetSeed()),
+        shared(shared) {
@@ -478,87 +544,0 @@ class Stats {
-class SharedState {
- public:
-  static const uint32_t SENTINEL = 0xffffffff;
-  explicitSharedState(StressTest* stress_test)
-      : cv_(&mu_),
-        seed_(FLAGS_seed),
-        max_key_(FLAGS_max_key),
-        log2_keys_per_lock_(FLAGS_log2_keys_per_lock),
-        num_threads_(FLAGS_threads),
-        num_initialized_(0),
-        num_populated_(0),
-        vote_reopen_(0),
-        num_done_(0),
-        start_(false),
-        start_verify_(false),
-        stress_test_(stress_test) {
-    if (FLAGS_test_batches_snapshots) {
-      key_locks_ = nullptr;
-      values_ = nullptr;
-      fprintf(stdout, "No lock creation because test_batches_snapshots set\n");
-      return;
-    }
-    values_ = new uint32_t[max_key_];
-    for (long i = 0; i < max_key_; i++) {
-      values_[i] = SENTINEL;
-    }
-    long num_locks = (max_key_ >> log2_keys_per_lock_);
-    if (max_key_ & ((1 << log2_keys_per_lock_) - 1)) {
-      num_locks++;
-    }
-    fprintf(stdout, "Creating %ld locks\n", num_locks);
-    key_locks_ = new port::Mutex[num_locks];
-  }
-  ~SharedState() = delete;
-  {
-    delete[] values_;
-    delete[] key_locks_;
-  }
-  port::Mutex* GetMutex() { return &mu_; }
-  port::CondVar* GetCondVar() { return &cv_; }
-  StressTest* GetStressTest() const { return stress_test_; }
-  long GetMaxKey() const { return max_key_; }
-  uint32_t GetNumThreads() const { return num_threads_; }
-  void IncInitialized() { num_initialized_++; }
-  void IncOperated() { num_populated_++; }
-  void IncDone() { num_done_++; }
-  void IncVotedReopen() { vote_reopen_ = (vote_reopen_ + 1) % num_threads_; }
-  bool AllInitialized() const { return num_initialized_ >= num_threads_; }
-  bool AllOperated() const { return num_populated_ >= num_threads_; }
-  bool AllDone() const { return num_done_ >= num_threads_; }
-  bool AllVotedReopen() { return (vote_reopen_ == 0); }
-  void SetStart() { start_ = true; }
-  void SetStartVerify() { start_verify_ = true; }
-  bool Started() const { return start_; }
-  bool VerifyStarted() const { return start_verify_; }
-  port::Mutex* GetMutexForKey(long key) {
-    return &key_locks_[key >> log2_keys_per_lock_];
-  }
-  void Put(long key, uint32_t value_base) { values_[key] = value_base; }
-  uint32_t Get(long key) const { return values_[key]; }
-  void Delete(long key) const { values_[key] = SENTINEL; }
-  uint32_t GetSeed() const { return seed_; }
- private:
-  port::Mutex mu_;
-  port::CondVar cv_;
-  const uint32_t seed_;
-  const long max_key_;
-  const uint32_t log2_keys_per_lock_;
-  const int num_threads_;
-  long num_initialized_;
-  long num_populated_;
-  long vote_reopen_;
-  long num_done_;
-  bool start_;
-  bool start_verify_;
-  StressTest* stress_test_;
-  uint32_t* values_;
-  port::Mutex* key_locks_;
-};
-struct ThreadState {
-  uint32_t tid;
-  Random rand;
-  SharedState* shared;
-  Stats stats;
-  ThreadState(uint32_t index, SharedState* shared)
-      : tid(index), rand(1000 + index + shared->GetSeed()), shared(shared) {}
-};
@@ -598,8 +577,0 @@ class StressTest {
-  {
-    for (auto cf : column_families_) {
-      delete cf;
-    }
-    column_families_.clear();
-    delete db_;
-    delete filter_policy_;
-  }
@@ -697,2 +669,4 @@ class StressTest {
-    std::string keys[10] = {"9", "8", "7", "6", "5", "4", "3", "2", "1", "0"};
-    std::string values[10] = {"9", "8", "7", "6", "5", "4", "3", "2", "1", "0"};
+    std::string keys[10] = {"9", "8", "7", "6", "5",
+                            "4", "3", "2", "1", "0"};
+    std::string values[10] = {"9", "8", "7", "6", "5",
+                              "4", "3", "2", "1", "0"};
@@ -723 +697,2 @@ class StressTest {
-    std::string keys[10] = {"9", "7", "5", "3", "1", "8", "6", "4", "2", "0"};
+    std::string keys[10] = {"9", "7", "5", "3", "1",
+                            "8", "6", "4", "2", "0"};
@@ -738,0 +714,42 @@ class StressTest {
+  Status MultiGet(ThreadState* thread, const ReadOptions& readoptions,
+                  ColumnFamilyHandle* column_family, const Slice& key,
+                  std::string* value) {
+    std::string keys[10] = {"0", "1", "2", "3", "4", "5", "6", "7", "8", "9"};
+    Slice key_slices[10];
+    std::string values[10];
+    ReadOptions readoptionscopy = readoptions;
+    readoptionscopy.snapshot = db_->GetSnapshot();
+    Status s;
+    for (int i = 0; i < 10; i++) {
+      keys[i] += key.ToString();
+      key_slices[i] = keys[i];
+      s = db_->Get(readoptionscopy, column_family, key_slices[i], value);
+      if (!s.ok() && !s.IsNotFound()) {
+        fprintf(stderr, "get error: %s\n", s.ToString().c_str());
+        values[i] = "";
+        thread->stats.AddErrors(1);
+      } else if (s.IsNotFound()) {
+        values[i] = "";
+        thread->stats.AddGets(1, 0);
+      } else {
+        values[i] = *value;
+        char expected_prefix = (keys[i])[0];
+        char actual_prefix = (values[i])[0];
+        if (actual_prefix != expected_prefix) {
+          fprintf(stderr, "error expected prefix = %c actual = %c\n",
+                  expected_prefix, actual_prefix);
+        }
+        (values[i])[0] = ' ';
+        thread->stats.AddGets(1, 1);
+      }
+    }
+    db_->ReleaseSnapshot(readoptionscopy.snapshot);
+    for (int i = 1; i < 10; i++) {
+      if (values[i] != values[0]) {
+        fprintf(stderr, "error : inconsistent values for key %s: %s, %s\n",
+                key.ToString().c_str(), values[0].c_str(),
+                values[i].c_str());
+      }
+    }
+    return s;
+  }
@@ -740 +757,2 @@ class StressTest {
-                         ColumnFamilyHandle* column_family, const Slice& key) {
+                         ColumnFamilyHandle* column_family,
+                         const Slice& key) {
@@ -776 +794,2 @@ class StressTest {
-                  prefixes[i].c_str(), values[0].c_str(), values[i].c_str());
+                  prefixes[i].c_str(), values[0].c_str(),
+                  values[i].c_str());
@@ -841 +860,2 @@ class StressTest {
-          } else {
+          }
+          else {
@@ -966 +985,0 @@ class StressTest {
-<<<<<<< HEAD
@@ -968,3 +986,0 @@ class StressTest {
-||||||| 45ad75db8
-=======
->>>>>>> 5aa81f04faf94361852117b7155f94473cf42a8e
@@ -1007,0 +1024 @@ class StressTest {
+          VerifyValue(cf, i, options, shared, from_db, s, true);
@@ -1011 +1027,0 @@ class StressTest {
-          VerifyValue(cf, i, options, shared, from_db, s, true);
@@ -1076 +1092,2 @@ class StressTest {
-    fprintf(stdout, "Ops per thread      : %lu\n",
+    fprintf(stdout,
+            "Ops per thread      : %lu\n",
@@ -1089 +1106,2 @@ class StressTest {
-    fprintf(stdout, "Iterations          : %lu\n",
+    fprintf(stdout,
+            "Iterations          : %lu\n",
@@ -1091 +1109,2 @@ class StressTest {
-    fprintf(stdout, "Max key             : %lu\n",
+    fprintf(stdout,
+            "Max key             : %lu\n",
@@ -1096 +1115,2 @@ class StressTest {
-    fprintf(stdout, "Batches/snapshots   : %d\n", FLAGS_test_batches_snapshots);
+    fprintf(stdout, "Batches/snapshots   : %d\n",
+            FLAGS_test_batches_snapshots);
@@ -1099 +1119,2 @@ class StressTest {
-    fprintf(stdout, "Deletes use filter  : %d\n", FLAGS_filter_deletes);
+    fprintf(stdout, "Deletes use filter  : %d\n",
+            FLAGS_filter_deletes);
@@ -1176,2 +1197 @@ class StressTest {
-      fprintf(
-          stderr,
+      fprintf(stderr,
@@ -1298,0 +1319 @@ class StressTest {
+ private:
@@ -1308,41 +1328,0 @@ class StressTest {
-  Status MultiGet(ThreadState* thread, const ReadOptions& readoptions,
-                  ColumnFamilyHandle* column_family, const Slice& key,
-                  std::string* value) {
-    std::string keys[10] = {"0", "1", "2", "3", "4", "5", "6", "7", "8", "9"};
-    Slice key_slices[10];
-    std::string values[10];
-    ReadOptions readoptionscopy = readoptions;
-    readoptionscopy.snapshot = db_->GetSnapshot();
-    Status s;
-    for (int i = 0; i < 10; i++) {
-      keys[i] += key.ToString();
-      key_slices[i] = keys[i];
-      s = db_->Get(readoptionscopy, column_family, key_slices[i], value);
-      if (!s.ok() && !s.IsNotFound()) {
-        fprintf(stderr, "get error: %s\n", s.ToString().c_str());
-        values[i] = "";
-        thread->stats.AddErrors(1);
-      } else if (s.IsNotFound()) {
-        values[i] = "";
-        thread->stats.AddGets(1, 0);
-      } else {
-        values[i] = *value;
-        char expected_prefix = (keys[i])[0];
-        char actual_prefix = (values[i])[0];
-        if (actual_prefix != expected_prefix) {
-          fprintf(stderr, "error expected prefix = %c actual = %c\n",
-                  expected_prefix, actual_prefix);
-        }
-        (values[i])[0] = ' ';
-        thread->stats.AddGets(1, 1);
-      }
-    }
-    db_->ReleaseSnapshot(readoptionscopy.snapshot);
-    for (int i = 1; i < 10; i++) {
-      if (values[i] != values[0]) {
-        fprintf(stderr, "error : inconsistent values for key %s: %s, %s\n",
-                key.ToString().c_str(), values[0].c_str(), values[i].c_str());
-      }
-    }
-    return s;
-  }
@@ -1377,2 +1357,2 @@ int main(int argc, char** argv) {
-  if ((FLAGS_readpercent + FLAGS_prefixpercent + FLAGS_writepercent +
-       FLAGS_delpercent + FLAGS_iterpercent) != 100) {
+  if ((FLAGS_readpercent + FLAGS_prefixpercent +
+       FLAGS_writepercent + FLAGS_delpercent + FLAGS_iterpercent) != 100) {
@@ -1391 +1371,2 @@ int main(int argc, char** argv) {
-            FLAGS_reopen, (unsigned long)FLAGS_ops_per_thread);
+              FLAGS_reopen,
+              (unsigned long)FLAGS_ops_per_thread);
